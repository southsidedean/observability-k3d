# manifests/monitoring/alerts/k8s-resource-alerts.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: k8s-resource-alerts
  labels:
    release: kube-prometheus-stack
spec:
  groups:
  - name: kubernetes.apps
    rules:
    - alert: KubePodCrashLooping
      expr: rate(kube_pod_container_status_restarts_total[15m]) * 60 * 5 > 3
      for: 15m
      labels:
        severity: critical
      annotations:
        summary: "Pod is crash-looping ({{ $labels.namespace }}/{{ $labels.pod }})"
        description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} in container '{{ $labels.container }}' is restarting frequently."

  - name: kubernetes.nodes
    rules:
    - alert: KubeNodeNotReady
      expr: kube_node_status_condition{condition="Ready",status="true"} == 0
      for: 10m
      labels:
        severity: critical
      annotations:
        summary: "Node is not ready ({{ $labels.node }})"
        description: "Node {{ $labels.node }} has been in a NotReady state for over 10 minutes."

    - alert: KubeNodeReadinessFlapping
      expr: sum(changes(kube_node_status_condition{condition="Ready",status="true"}[15m])) by (node) > 2
      for: 15m
      labels:
        severity: warning
      annotations:
        summary: "Node readiness is flapping ({{ $labels.node }})"
        description: "Node {{ $labels.node }} is flapping between Ready and NotReady states."

  - name: kubernetes.system
    rules:
    - alert: KubeAPIDown
      # This alert relies on the 'kubernetes-apiserver' probe created in manifests/monitoring/probes
      expr: probe_success{job="kubernetes-apiserver"} == 0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Kubernetes API server is down"
        description: "The Kubernetes API server has been unreachable for more than 5 minutes, as detected by the Blackbox Exporter."